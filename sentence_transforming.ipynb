{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Analysis & Sentence embeddings.\n",
    "To do similarity analysis on all documents we want an embedding for each document. An embedding is a vector representation of the document. I will use sentence's to demonstrate the concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity.\n",
    "Sentence embeddings are vectors that represent the meaning of a sentence. The cosine similarity between two vectors calculates the cosine of the angle between them. \n",
    "- If the vectors are similar, the cosine similarity will be close to 1. \n",
    "- if the vectors are orthogonal(unrelated), the cosine similarity will be 0.\n",
    "- If the vectors are dissimilar, the cosine similarity will be close to -1.\n",
    "\n",
    "the cosine similarity is calculated as follows:\n",
    "$$\\text{cos}(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}$$\n",
    "where $\\mathbf{A} \\cdot \\mathbf{B}$ is the dot product of the vectors and $\\|\\mathbf{A}\\|\\|\\mathbf{B}\\|$ is the product of the magnitudes of the vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"The cosine similarity between two sentence embeddings.\"\"\"\n",
    "    return (a@b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformers\n",
    "I am using the `sentence-transformers` library to generate embeddings for the sentences. The library provides a simple interface to generate embeddings for sentences. The library can be installed using the following command:\n",
    "```bash\n",
    "pip install sentence-transformers\n",
    "```\n",
    "I will use the all-MiniLM-L6-v2 model to generate embeddings for each document. Info on the model can be found [here](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model we want to use. Most Hugging Face models are supported. all-MiniLM-L6-v2 is a small model that works well for demonstration.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stand-in data pool of plain text documents.\n",
    "documents = [\n",
    "    'We have 200 costumers around the world with 1000 products.',\n",
    "    'We have costumers world wide with products in the thousands.',\n",
    "    'Our products are known by costumers all over the world.',\n",
    "    'Our company makes ice cream.',\n",
    "]\n",
    "doc_embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a dictionary of embedded documents to stand in for a vector database. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = dict(zip([f'doc{i}' for i in range(len(documents))], list(doc_embeddings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Analysis.\n",
    "Wow that we have embeddings for all documents organized, its easy to calculate the similarity between any two documents. The first 3 documents are similar, so the cosine similarity between them will be close to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.88820124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings_dict['doc0'], embeddings_dict['doc1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.86992204)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings_dict['doc1'], embeddings_dict['doc2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.72208786)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings_dict['doc2'], embeddings_dict['doc0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last document about ice cream is dissimilar to the first 3, with a cosine similarity around 0.24. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.24467042)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings_dict['doc3'], embeddings_dict['doc0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAS_474",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
